# InEight Document AI Chatbot - Implementation Plan (Free Tier MVP)

# Goal Description
Build a **free-tier MVP** using **PostgreSQL + pgvector** and **Ollama + Llama 3** with a **provider abstraction layer** that enables switching to Azure services via configuration only (no code changes).

**MVP Scope (Phase 1)**: Implement free-tier providers only
**Phase 2**: Add Azure providers (already architected, just config switch)

## Architecture Strategy: Provider Abstraction Pattern

### Design Principle
All AI and vector search operations go through **interfaces**, with **multiple implementations** selected via configuration:

```
Application Code â†’ Interface â†’ [Config Switch] â†’ Provider Implementation
                                      â†“
                            Free: Ollama/pgvector
                            Prod: Azure OpenAI/AI Search
```

**Benefit**: Change `appsettings.json` â†’ Instant provider switch (no code changes)

---

## User Review Required

> [!IMPORTANT]
> **Phase 1 MVP Limitations (Free Tier)**:
> - **Cost**: $0/month (all self-hosted)
> - **Performance**: 2-5 second response time (vs 1-2s with Azure)
> - **Scalability**: Single server (no auto-scale)
> - **Uptime**: Depends on hosting (99% self-hosted, 95% free cloud tiers)
> 
> **Good for**: Development, testing, low-traffic production
> 
> **Upgrade Path**: Change 2 config values â†’ Azure providers activate (Phase 2)

> [!NOTE]
> **MVP Implementation Scope**:
> - âœ… Provider abstraction interfaces (future-proof)
> - âœ… Ollama provider (free AI)
> - âœ… pgvector provider (free vector search)
> - ðŸ“ Azure providers (stub/template only, not implemented in MVP)
> 
> Phase 2 will implement Azure providers with zero changes to application code.

> [!WARNING]
> **DMS Compatibility Note** (see `5. DMS_Implementation_Plan.md`):
> The Chatbot connects to a **legacy DMS built with .NET Framework 4.8.1 + EF6**. Key considerations:
> - **User Table**: Read from `AspNetUsers` (ASP.NET Identity 2.0), not a custom Users table
> - **Connection**: Use SQL Server connection string to DMS database
> - **Table Schema**: EF6 naming conventions (e.g., `dbo.Documents`, `dbo.Projects`)
> - **User ID**: Integer type (`int`) for user IDs
> - **Access Control**: Query `ProjectUsers` join table + `Projects.ManagerId` for permissions

---

## Proposed Changes

Project location: `d:\\Code\\ineight\\projects\\InEightDocumentAISuite`

---

### Phase 1: Foundation & Abstraction Layer

#### [NEW] [InEightDocBot.sln](file:///d:/Code/ineight/projects/InEightDocumentAISuite/InEightDocBot.sln)
Solution structure:
```
InEightDocBot.sln
â”œâ”€â”€ InEightDocBot.Service (Web API)
â”œâ”€â”€ InEightDocBot.Core (Domain models, interfaces)
â”œâ”€â”€ InEightDocBot.Infrastructure (Provider implementations)
â””â”€â”€ InEightDocBot.Widget (React chat widget)
```

#### [NEW] [InEightDocBot.Core](file:///d:/Code/ineight/projects/InEightDocumentAISuite/InEightDocBot.Core/)
Class library for shared abstractions.

**Interfaces**:

##### [Interfaces/IAIProvider.cs](file:///d:/Code/ineight/projects/InEightDocumentAISuite/InEightDocBot.Core/Interfaces/IAIProvider.cs)
```csharp
public interface IAIProvider
{
    Task<string> GenerateCompletionAsync(
        string systemPrompt, 
        string userPrompt, 
        CancellationToken ct = default);
    
    Task<float[]> GenerateEmbeddingAsync(
        string text, 
        CancellationToken ct = default);
    
    string ProviderName { get; }
    int EmbeddingDimensions { get; }
}
```

##### [Interfaces/IVectorSearchProvider.cs](file:///d:/Code/ineight/projects/InEightDocumentAISuite/InEightDocBot.Core/Interfaces/IVectorSearchProvider.cs)
```csharp
public interface IVectorSearchProvider
{
    Task IndexDocumentAsync(
        int documentId, 
        string text, 
        float[] embedding, 
        Dictionary<string, object> metadata,
        int[] accessibleUserIds,
        CancellationToken ct = default);
    
    Task<SearchResult[]> SearchAsync(
        float[] queryEmbedding, 
        int userId, 
        int topK = 10,
        CancellationToken ct = default);
    
    Task DeleteDocumentAsync(int documentId, CancellationToken ct = default);
    
    string ProviderName { get; }
}

public record SearchResult(
    int DocumentId,
    string Text,
    Dictionary<string, object> Metadata,
    float Distance
);
```

#### [NEW] [InEightDocBot.Infrastructure](file:///d:/Code/ineight/projects/InEightDocumentAISuite/InEightDocBot.Infrastructure/)
Provider implementations.

##### [Providers/OllamaProvider.cs](file:///d:/Code/ineight/projects/InEightDocumentAISuite/InEightDocBot.Infrastructure/Providers/OllamaProvider.cs)
**[IMPLEMENT IN MVP]** - Full implementation
```csharp
public class OllamaProvider : IAIProvider
{
    private readonly HttpClient _httpClient;
    private readonly IOptions<OllamaSettings> _settings;
    
    public string ProviderName => "Ollama";
    public int EmbeddingDimensions => 384; // nomic-embed-text
    
    public async Task<string> GenerateCompletionAsync(
        string systemPrompt, 
        string userPrompt, 
        CancellationToken ct = default)
    {
        var request = new
        {
            model = _settings.Value.Model,
            prompt = $"{systemPrompt}\n\n{userPrompt}",
            stream = false
        };
        
        var response = await _httpClient.PostAsJsonAsync(
            $"{_settings.Value.Endpoint}/api/generate", 
            request, ct);
        
        var result = await response.Content.ReadFromJsonAsync<OllamaResponse>(ct);
        return result.Response;
    }
    
    public async Task<float[]> GenerateEmbeddingAsync(
        string text, 
        CancellationToken ct = default)
    {
        var request = new
        {
            model = _settings.Value.EmbeddingModel,
            prompt = text
        };
        
        var response = await _httpClient.PostAsJsonAsync(
            $"{_settings.Value.Endpoint}/api/embeddings", 
            request, ct);
        
        var result = await response.Content.ReadFromJsonAsync<OllamaEmbeddingResponse>(ct);
        return result.Embedding;
    }
}
```

##### [Providers/PgVectorProvider.cs](file:///d:/Code/ineight/projects/InEightDocumentAISuite/InEightDocBot.Infrastructure/Providers/PgVectorProvider.cs)
**[IMPLEMENT IN MVP]** - Full implementation
```csharp
public class PgVectorProvider : IVectorSearchProvider
{
    private readonly NpgsqlDataSource _dataSource;
    
    public string ProviderName => "PostgreSQL + pgvector";
    
    public async Task IndexDocumentAsync(
        int documentId, 
        string text, 
        float[] embedding, 
        Dictionary<string, object> metadata,
        int[] accessibleUserIds,
        CancellationToken ct = default)
    {
        await using var cmd = _dataSource.CreateCommand(@"
            INSERT INTO document_embeddings 
            (document_id, chunk_text, embedding, metadata, user_access_list)
            VALUES ($1, $2, $3, $4, $5)
            ON CONFLICT (document_id) 
            DO UPDATE SET 
                chunk_text = EXCLUDED.chunk_text,
                embedding = EXCLUDED.embedding,
                metadata = EXCLUDED.metadata,
                user_access_list = EXCLUDED.user_access_list");
        
        cmd.Parameters.AddWithValue(documentId);
        cmd.Parameters.AddWithValue(text);
        cmd.Parameters.AddWithValue(new Vector(embedding));
        cmd.Parameters.AddWithValue(JsonSerializer.Serialize(metadata));
        cmd.Parameters.AddWithValue(accessibleUserIds);
        
        await cmd.ExecuteNonQueryAsync(ct);
    }
    
    public async Task<SearchResult[]> SearchAsync(
        float[] queryEmbedding, 
        int userId, 
        int topK = 10,
        CancellationToken ct = default)
    {
        await using var cmd = _dataSource.CreateCommand(@"
            SELECT document_id, chunk_text, metadata,
                   embedding <=> $1 AS distance
            FROM document_embeddings
            WHERE $2 = ANY(user_access_list)
            ORDER BY distance
            LIMIT $3");
        
        cmd.Parameters.AddWithValue(new Vector(queryEmbedding));
        cmd.Parameters.AddWithValue(userId);
        cmd.Parameters.AddWithValue(topK);
        
        var results = new List<SearchResult>();
        await using var reader = await cmd.ExecuteReaderAsync(ct);
        
        while (await reader.ReadAsync(ct))
        {
            results.Add(new SearchResult(
                DocumentId: reader.GetInt32(0),
                Text: reader.GetString(1),
                Metadata: JsonSerializer.Deserialize<Dictionary<string, object>>(
                    reader.GetString(2)),
                Distance: reader.GetFloat(3)
            ));
        }
        
        return results.ToArray();
    }
}
```

##### [Providers/AzureOpenAIProvider.cs](file:///d:/Code/ineight/projects/InEightDocumentAISuite/InEightDocBot.Infrastructure/Providers/AzureOpenAIProvider.cs)
**[STUB ONLY IN MVP]** - Template for Phase 2
```csharp
public class AzureOpenAIProvider : IAIProvider
{
    // TODO: Phase 2 - Implement using Azure.AI.OpenAI NuGet
    public string ProviderName => "Azure OpenAI";
    public int EmbeddingDimensions => 1536; // text-embedding-ada-002
    
    public Task<string> GenerateCompletionAsync(
        string systemPrompt, 
        string userPrompt, 
        CancellationToken ct = default)
    {
        throw new NotImplementedException("Phase 2: Install Azure.AI.OpenAI NuGet and implement");
    }
    
    public Task<float[]> GenerateEmbeddingAsync(string text, CancellationToken ct = default)
    {
        throw new NotImplementedException("Phase 2: Use Azure OpenAI embeddings API");
    }
}
```

##### [Providers/AzureAISearchProvider.cs](file:///d:/Code/ineight/projects/InEightDocumentAISuite/InEightDocBot.Infrastructure/Providers/AzureAISearchProvider.cs)
**[STUB ONLY IN MVP]** - Template for Phase 2
```csharp
public class AzureAISearchProvider : IVectorSearchProvider
{
    // TODO: Phase 2 - Implement using Azure.Search.Documents NuGet
    public string ProviderName => "Azure AI Search";
    
    public Task IndexDocumentAsync(
        int documentId, 
        string text, 
        float[] embedding, 
        Dictionary<string, object> metadata,
        int[] accessibleUserIds,
        CancellationToken ct = default)
    {
        throw new NotImplementedException("Phase 2: Use SearchClient.UploadDocumentsAsync");
    }
    
    public Task<SearchResult[]> SearchAsync(
        float[] queryEmbedding, 
        int userId, 
        int topK = 10,
        CancellationToken ct = default)
    {
        throw new NotImplementedException("Phase 2: Use SearchClient.SearchAsync with vector");
    }
    
    public Task DeleteDocumentAsync(int documentId, CancellationToken ct = default)
    {
        throw new NotImplementedException("Phase 2");
    }
}
```

#### [NEW] [Configuration/ProviderSettingsExtensions.cs](file:///d:/Code/ineight/projects/InEightDocumentAISuite/InEightDocBot.Service/Configuration/ProviderSettingsExtensions.cs)
Dependency injection configuration based on settings:

```csharp
public static class ProviderSettingsExtensions
{
    public static IServiceCollection AddAIProviders(
        this IServiceCollection services, 
        IConfiguration configuration)
    {
        var aiProvider = configuration["AI:Provider"];
        var vectorProvider = configuration["AI:VectorStore"];
        
        // Register AI Provider
        services.Configure<OllamaSettings>(configuration.GetSection("AI:Ollama"));
        services.Configure<AzureOpenAISettings>(configuration.GetSection("AI:AzureOpenAI"));
        
        services.AddSingleton<IAIProvider>(sp =>
        {
            return aiProvider switch
            {
                "Ollama" => new OllamaProvider(
                    sp.GetRequiredService<HttpClient>(),
                    sp.GetRequiredService<IOptions<OllamaSettings>>()),
                "AzureOpenAI" => new AzureOpenAIProvider(
                    sp.GetRequiredService<IOptions<AzureOpenAISettings>>()),
                _ => throw new InvalidOperationException($"Unknown AI provider: {aiProvider}")
            };
        });
        
        // Register Vector Search Provider
        services.AddSingleton<IVectorSearchProvider>(sp =>
        {
            return vectorProvider switch
            {
                "PgVector" => new PgVectorProvider(
                    sp.GetRequiredService<NpgsqlDataSource>()),
                "AzureAISearch" => new AzureAISearchProvider(
                    sp.GetRequiredService<IOptions<AzureAISearchSettings>>()),
                _ => throw new InvalidOperationException($"Unknown vector provider: {vectorProvider}")
            };
        });
        
        return services;
    }
}
```

#### [NEW] [appsettings.json](file:///d:/Code/ineight/projects/InEightDocumentAISuite/InEightDocBot.Service/appsettings.json)
**Configuration template supporting both providers**:

```json
{
  "AI": {
    "Provider": "Ollama",
    "VectorStore": "PgVector",
    
    "Ollama": {
      "Endpoint": "http://localhost:11434",
      "Model": "llama3",
      "EmbeddingModel": "nomic-embed-text"
    },
    
    "AzureOpenAI": {
      "Endpoint": "https://[PHASE-2].openai.azure.com/",
      "ApiKey": "[PHASE-2-KEY]",
      "DeploymentName": "gpt-4o",
      "EmbeddingDeployment": "text-embedding-ada-002"
    },
    
    "AzureAISearch": {
      "Endpoint": "https://[PHASE-2].search.windows.net",
      "ApiKey": "[PHASE-2-KEY]",
      "IndexName": "documents"
    }
  },
  
  "ConnectionStrings": {
    "PostgreSQL": "Host=localhost;Database=ineightdocbot;Username=postgres;Password=dev123",
    "AzureSQL": "[PHASE-2]"
  }
}
```

**To switch to Azure (Phase 2)**: Change 2 lines:
```json
"Provider": "AzureOpenAI",
"VectorStore": "AzureAISearch",
```

---

### Phase 2: Database Setup (PostgreSQL + pgvector)

#### [NEW] [Database/PostgreSQL/setup.sql](file:///d:/Code/ineight/projects/InEightDocumentAISuite/Database/PostgreSQL/setup.sql)
```sql
-- Enable pgvector extension
CREATE EXTENSION IF NOT EXISTS vector;

-- Document embeddings table
CREATE TABLE document_embeddings (
    id SERIAL PRIMARY KEY,
    document_id INT NOT NULL UNIQUE,
    chunk_text TEXT NOT NULL,
    embedding vector(384), -- nomic-embed-text dimensions
    metadata JSONB,
    user_access_list INT[],
    created_at TIMESTAMP DEFAULT NOW(),
    updated_at TIMESTAMP DEFAULT NOW()
);

-- Create index for fast similarity search
CREATE INDEX document_embeddings_embedding_idx 
ON document_embeddings 
USING ivfflat (embedding vector_cosine_ops)
WITH (lists = 100);

-- Index for user access filtering
CREATE INDEX document_embeddings_access_idx 
ON document_embeddings 
USING GIN (user_access_list);

-- Linked items embeddings (RFI, Transmittals, etc.)
CREATE TABLE linked_item_embeddings (
    id SERIAL PRIMARY KEY,
    item_id INT NOT NULL,
    item_type VARCHAR(50) NOT NULL,
    document_id INT NOT NULL,
    chunk_text TEXT NOT NULL,
    embedding vector(384),
    metadata JSONB,
    user_access_list INT[],
    created_at TIMESTAMP DEFAULT NOW()
);

CREATE INDEX linked_item_embeddings_embedding_idx 
ON linked_item_embeddings 
USING ivfflat (embedding vector_cosine_ops)
WITH (lists = 50);

-- Document actions embeddings
CREATE TABLE action_embeddings (
    id SERIAL PRIMARY KEY,
    action_id INT NOT NULL,
    document_id INT NOT NULL,
    action_type VARCHAR(100),
    chunk_text TEXT NOT NULL,
    embedding vector(384),
    metadata JSONB,
    user_access_list INT[],
    created_at TIMESTAMP DEFAULT NOW()
);

CREATE INDEX action_embeddings_embedding_idx 
ON action_embeddings 
USING ivfflat (embedding vector_cosine_ops)
WITH (lists = 50);
```

#### [RUN] Setup PostgreSQL Locally (MVP)

**Option A: Docker (Recommended for development)**
```bash
docker run --name postgres-ineight \
  -e POSTGRES_PASSWORD=dev123 \
  -e POSTGRES_DB=ineightdocbot \
  -p 5432:5432 \
  -d ankane/pgvector:latest

# Run setup script
docker exec -i postgres-ineight psql -U postgres -d ineightdocbot < Database/PostgreSQL/setup.sql
```

**Option B: Local PostgreSQL Installation**
```bash
# Ubuntu/Debian
sudo apt install postgresql-16 postgresql-16-pgvector
sudo -u postgres createdb ineightdocbot
sudo -u postgres psql ineightdocbot < Database/PostgreSQL/setup.sql
```

---

### Phase 3: Ollama Setup (Local AI)

#### [RUN] Install Ollama

**Windows/Linux/Mac**:
```bash
# Install Ollama
curl -fsSL https://ollama.com/install.sh | sh

# Pull models
ollama pull llama3                # 4.7GB - Main LLM
ollama pull nomic-embed-text      # 274MB - Embedding model

# Start Ollama server (runs on localhost:11434)
ollama serve
```

#### [RUN] Test Ollama

```bash
# Test completion
curl http://localhost:11434/api/generate -d '{
  "model": "llama3",
  "prompt": "What is RAG?",
  "stream": false
}'

# Test embeddings
curl http://localhost:11434/api/embeddings -d '{
  "model": "nomic-embed-text",
  "prompt": "Document about safety protocols"
}'
```

---

### Phase 4: Core Services Implementation

#### [NEW] [Services/MetadataSyncService.cs](file:///d:/Code/ineight/projects/InEightDocumentAISuite/InEightDocBot.Service/Services/MetadataSyncService.cs)
Uses provider abstraction:

```csharp
public class MetadataSyncService : BackgroundService
{
    private readonly IAIProvider _aiProvider;
    private readonly IVectorSearchProvider _vectorSearch;
    private readonly IDocumentRepository _documentRepo;
    
    protected override async Task ExecuteAsync(CancellationToken ct)
    {
        while (!ct.IsCancellationRequested)
        {
            await SyncMetadataAsync(ct);
            await Task.Delay(TimeSpan.FromHours(4), ct);
        }
    }
    
    private async Task SyncMetadataAsync(CancellationToken ct)
    {
        var documents = await _documentRepo.GetAllAsync(ct);
        
        foreach (var doc in documents)
        {
            // Format metadata as text
            var text = FormatDocumentMetadata(doc);
            
            // Generate embedding (works with any IAIProvider)
            var embedding = await _aiProvider.GenerateEmbeddingAsync(text, ct);
            
            // Index (works with any IVectorSearchProvider)
            await _vectorSearch.IndexDocumentAsync(
                doc.Id,
                text,
                embedding,
                doc.Metadata,
                doc.AccessibleUserIds,
                ct);
        }
    }
    
    private string FormatDocumentMetadata(Document doc)
    {
        return $"Document '{doc.Name}' (ID: {doc.Id}), " +
               $"Status: {doc.Status}, " +
               $"Type: {doc.Type}, " +
               $"Created: {doc.UploadedAt:yyyy-MM-dd} by {doc.UploadedBy}, " +
               $"Project: {doc.ProjectName}, " +
               $"Transmittal: {doc.TransmittalNumber ?? "None"}";
    }
}
```

#### [NEW] [Services/RAGOrchestrator.cs](file:///d:/Code/ineight/projects/InEightDocumentAISuite/InEightDocBot.Service/Services/RAGOrchestrator.cs)
Provider-agnostic RAG pipeline:

```csharp
public class RAGOrchestrator
{
    private readonly IAIProvider _aiProvider;
    private readonly IVectorSearchProvider _vectorSearch;
    
    public async Task<ChatResponse> ProcessQueryAsync(
        string userQuery, 
        int userId, 
        CancellationToken ct = default)
    {
        // 1. Generate query embedding
        var queryEmbedding = await _aiProvider.GenerateEmbeddingAsync(userQuery, ct);
        
        // 2. Semantic search (respects user access)
        var results = await _vectorSearch.SearchAsync(queryEmbedding, userId, topK: 10, ct);
        
        // 3. Build context
        var context = string.Join("\n\n", results.Select(r => r.Text));
        
        // 4. Generate answer
        var systemPrompt = "You are a helpful document management assistant. " +
                          "Answer questions based ONLY on the provided context.";
        var userPrompt = $"Context:\n{context}\n\nQuestion: {userQuery}";
        
        var answer = await _aiProvider.GenerateCompletionAsync(systemPrompt, userPrompt, ct);
        
        // 5. Calculate confidence based on distance
        var avgDistance = results.Average(r => r.Distance);
        var confidence = 1.0f - Math.Min(avgDistance, 1.0f);
        
        return new ChatResponse
        {
            Answer = answer,
            DocumentIds = results.Select(r => r.DocumentId).ToArray(),
            Confidence = confidence
        };
    }
}
```

**Key Point**: This code works with **both** Ollama and Azure OpenAI. Change config â†’ different provider executes.

---

### Phase 5: API Endpoints

#### [NEW] [Controllers/ChatController.cs](file:///d:/Code/ineight/projects/InEightDocumentAISuite/InEightDocBot.Service/Controllers/ChatController.cs)
```csharp
[ApiController]
[Route("api/chat")]
public class ChatController : ControllerBase
{
    private readonly RAGOrchestrator _ragOrchestrator;
    
    [HttpPost("message")]
    public async Task<IActionResult> SendMessage(
        [FromBody] ChatRequest request,
        CancellationToken ct)
    {
        var userId = GetUserIdFromJwt();
        
        var response = await _ragOrchestrator.ProcessQueryAsync(
            request.Query, 
            userId, 
            ct);
        
        return Ok(new
        {
            answer = response.Answer,
            links = response.DocumentIds.Select(id => new
            {
                type = "document",
                id = id,
                url = $"/documents/{id}"
            }),
            confidence = response.Confidence
        });
    }
}
```

---

### Phase 6: React Chat Widget

#### [NEW] [InEightDocBot.Widget/src/services/apiClient.ts](file:///d:/Code/ineight/projects/InEightDocumentAISuite/InEightDocBot.Widget/src/services/apiClient.ts)
```typescript
export async function sendMessage(query: string, token: string) {
  const response = await fetch('/api/chat/message', {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
      'Authorization': `Bearer ${token}`
    },
    body: JSON.stringify({ query })
  });
  
  return await response.json();
}
```

Widget implementation same as main plan.

---

### Phase 7: Testing & Verification

#### [RUN] End-to-End Test

**1. Start All Services**:
```bash
# Terminal 1: PostgreSQL (if using Docker)
docker start postgres-ineight

# Terminal 2: Ollama
ollama serve

# Terminal 3: .NET API
cd InEightDocBot.Service
dotnet run
```

**2. Verify Provider Selection**:
```bash
# Check logs for provider confirmation
# Should see: "Using AI Provider: Ollama"
# Should see: "Using Vector Store: PostgreSQL + pgvector"
```

**3. Trigger Metadata Sync**:
```bash
curl -X POST http://localhost:5000/api/admin/sync-metadata
```

**4. Test Chat**:
```bash
curl -X POST http://localhost:5000/api/chat/message \
  -H "Authorization: Bearer <test-jwt>" \
  -H "Content-Type: application/json" \
  -d '{"query":"Show me IFC drawings"}'
```

**Expected Response**:
```json
{
  "answer": "Based on the documents, I found 3 IFC drawings...",
  "links": [
    {"type": "document", "id": 123, "url": "/documents/123"}
  ],
  "confidence": 0.87
}
```

#### [RUN] Performance Benchmarks (Free Tier)

```bash
# Measure embedding generation
# Expected: ~10ms per document (local, fast)

# Measure search latency
# Expected: 50-100ms for similarity search in pgvector

# Measure chat response time
# Expected: 2-5 seconds total (Ollama on CPU)
```

---

## Phase 2 Upgrade: Switching to Azure (Future)

### Step 1: Implement Azure Providers

Remove `NotImplementedException` from:
- `AzureOpenAIProvider.cs`
- `AzureAISearchProvider.cs`

Add NuGet packages:
```bash
dotnet add package Azure.AI.OpenAI
dotnet add package Azure.Search.Documents
```

### Step 2: Update Configuration

**appsettings.Production.json**:
```json
{
  "AI": {
    "Provider": "AzureOpenAI",
    "VectorStore": "AzureAISearch",
    
    "AzureOpenAI": {
      "Endpoint": "https://myinstance.openai.azure.com/",
      "ApiKey": "<actual-key>",
      "DeploymentName": "gpt-4o",
      "EmbeddingDeployment": "text-embedding-ada-002"
    },
    
    "AzureAISearch": {
      "Endpoint": "https://myinstance.search.windows.net",
      "ApiKey": "<actual-key>",
      "IndexName": "documents"
    }
  }
}
```

### Step 3: Migrate Embeddings (One-Time)

```csharp
// Export from pgvector
var documents = await pgVectorProvider.GetAllDocumentsAsync();

// Re-index to Azure AI Search
foreach (var doc in documents)
{
    // Re-generate embeddings with Azure OpenAI (1536-dim)
    var newEmbedding = await azureOpenAI.GenerateEmbeddingAsync(doc.Text);
    await azureAISearch.IndexDocumentAsync(doc.Id, doc.Text, newEmbedding, ...);
}
```

### Step 4: Deploy & Test

```bash
# Deploy with production config
dotnet publish -c Release
az webapp deploy --name ineightbot --resource-group ... --src-path ./publish.zip

# Test
curl https://ineightbot.azurewebsites.net/api/chat/message -d '...'
```

**Result**: Same application code, now running on Azure with better performance (1-2s responses).

---

## Cost Summary

### MVP (Free Tier)
- PostgreSQL (Docker): $0
- Ollama (local): $0
- .NET Hosting (self-hosted): $0
- **Total**: **$0/month**

### Phase 2 (Azure)
- Azure OpenAI (gpt-4o, 5M tokens): $25
- Azure AI Search (Basic): $75
- Azure App Service (B1): $13
- **Total**: **$113/month**

**Savings by starting free**: $113/month during development

---

## Implementation Timeline

### Week 1: Foundation
- Day 1-2: Project setup, interfaces, provider abstraction
- Day 3: PostgreSQL + pgvector setup
- Day 4: Ollama installation and testing
- Day 5: Provider implementations (Ollama, PgVector)

### Week 2: Core Services
- Day 1-2: MetadataSyncService
- Day 3: RAGOrchestrator
- Day 4: ChatController
- Day 5: Testing & debugging

### Week 3: Widget & Integration
- Day 1-3: React widget
- Day 4: JWT integration
- Day 5: End-to-end testing

### Week 4: Polish & Deployment
- Day 1-2: Performance optimization
- Day 3: Documentation (Azure provider stubs)
- Day 4: Self-hosted deployment
- Day 5: Final testing & handoff

**Total**: 4 weeks for free-tier MVP

**Phase 2** (Azure upgrade): 1-2 days to implement providers + deploy

---

## Success Criteria

### MVP (Phase 1)
âœ… Chat responds in 2-5 seconds
âœ… Embeddings indexed in pgvector
âœ… User security respected (access filtering)
âœ… Configuration switching works (tested by changing config to Azure and seeing appropriate error)
âœ… $0/month operational cost

### Phase 2 (Future)
âœ… Azure providers implemented
âœ… Chat responds in 1-2 seconds
âœ… Production-ready scalability
âœ… Config switch from Ollama â†’ Azure works seamlessly
